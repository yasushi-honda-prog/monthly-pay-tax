"""æ¥­å‹™ãƒã‚§ãƒƒã‚¯ç®¡ç†è¡¨ï¼ˆchecker/adminå°‚ç”¨ï¼‰

ãƒ¡ãƒ³ãƒãƒ¼ã®è£œåŠ©ï¼†ç«‹æ›¿å ±å‘Šã‚’ç¢ºèªã—ã€ãƒã‚§ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»ãƒ¡ãƒ¢ã‚’ç®¡ç†ã™ã‚‹ã€‚
"""

import json
import logging
from datetime import datetime, timezone

import pandas as pd
import streamlit as st
from google.cloud import bigquery

from lib.auth import require_checker
from lib.bq_client import get_bq_client
from lib.constants import PROJECT_ID, DATASET, CHECK_LOGS_TABLE
from lib.ui_helpers import clean_numeric_scalar, fill_empty_nickname, render_kpi, render_sidebar_year_month

logger = logging.getLogger(__name__)

# --- èªè¨¼ãƒã‚§ãƒƒã‚¯ ---
email = st.session_state.get("user_email", "")
role = st.session_state.get("user_role", "")
require_checker(email, role)

st.header("æ¥­å‹™ãƒã‚§ãƒƒã‚¯ç®¡ç†è¡¨")
st.caption("ãƒ¡ãƒ³ãƒãƒ¼ã®è£œåŠ©ï¼†ç«‹æ›¿å ±å‘Šã‚’ç¢ºèªãƒ»ç®¡ç†ã—ã¾ã™")

CHECK_STATUSES = ["æœªç¢ºèª", "ç¢ºèªä¸­", "ç¢ºèªå®Œäº†", "å·®æˆ»ã—"]
STATUS_ICONS = {"æœªç¢ºèª": "â¬œ", "ç¢ºèªä¸­": "ğŸ”µ", "ç¢ºèªå®Œäº†": "âœ…", "å·®æˆ»ã—": "ğŸ”´"}


def _is_complete(val) -> bool:
    """æœˆç· ã‚å®Œäº†åˆ¤å®š"""
    return str(val).strip().lower() in ("true", "1", "â—‹", "æ¸ˆ")


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.markdown("### âœ… æ¥­å‹™ãƒã‚§ãƒƒã‚¯")
    st.divider()

    selected_year, selected_month = render_sidebar_year_month(
        year_key="check_year", month_key="check_month",
    )

    st.markdown('<div class="sidebar-section-title">ãƒ•ã‚£ãƒ«ã‚¿</div>', unsafe_allow_html=True)
    status_filter = st.selectbox(
        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", ["ã™ã¹ã¦"] + CHECK_STATUSES, key="chk_filter",
    )
    name_search = st.text_input(
        "åå‰æ¤œç´¢", key="chk_search",
        placeholder="ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã§çµã‚Šè¾¼ã¿...",
        label_visibility="collapsed",
    )


# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
@st.cache_data(ttl=300)
def load_check_data(year: int, month: int):
    """ãƒ¡ãƒ³ãƒãƒ¼ + hojo + check_logs ã‚’çµåˆã—ã¦å–å¾—"""
    client = get_bq_client()
    query = f"""
    SELECT
        m.report_url,
        m.nickname,
        m.member_id,
        h.hours,
        h.compensation,
        h.dx_subsidy,
        h.reimbursement,
        h.total_amount,
        h.monthly_complete,
        cl.status AS check_status,
        cl.checker_email,
        cl.memo,
        cl.action_log,
        cl.updated_at AS check_updated_at
    FROM `{PROJECT_ID}.{DATASET}.members` m
    LEFT JOIN `{PROJECT_ID}.{DATASET}.v_hojo_enriched` h
        ON m.report_url = h.source_url
        AND h.year = @year AND h.month = @month
    LEFT JOIN `{CHECK_LOGS_TABLE}` cl
        ON m.report_url = cl.source_url
        AND cl.year = @year AND cl.month = @month
    WHERE m.report_url IS NOT NULL
    ORDER BY m.nickname
    """
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("year", "INT64", year),
            bigquery.ScalarQueryParameter("month", "INT64", month),
        ]
    )
    return client.query(query, job_config=job_config).to_dataframe()


def save_check(source_url, year, month, status, memo, checker_email, existing_log, action_desc, expected_updated_at=None):
    """ãƒã‚§ãƒƒã‚¯ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆMERGE + æ¥½è¦³çš„ãƒ­ãƒƒã‚¯ï¼‰"""
    client = get_bq_client()

    # æ“ä½œãƒ­ã‚°è¿½è¨˜ï¼ˆå‹å®‰å…¨ï¼‰
    try:
        logs = json.loads(existing_log) if existing_log and pd.notna(existing_log) else []
        if not isinstance(logs, list):
            logs = []
    except (json.JSONDecodeError, TypeError):
        logs = []
    logs = [e for e in logs if isinstance(e, dict)]
    logs.append({
        "ts": datetime.now(timezone.utc).isoformat(),
        "user": checker_email,
        "action": action_desc,
    })
    new_log = json.dumps(logs, ensure_ascii=False)

    params = [
        bigquery.ScalarQueryParameter("source_url", "STRING", source_url),
        bigquery.ScalarQueryParameter("year", "INT64", year),
        bigquery.ScalarQueryParameter("month", "INT64", month),
        bigquery.ScalarQueryParameter("status", "STRING", status),
        bigquery.ScalarQueryParameter("checker_email", "STRING", checker_email),
        bigquery.ScalarQueryParameter("memo", "STRING", memo or None),
        bigquery.ScalarQueryParameter("action_log", "STRING", new_log),
    ]

    # æ¥½è¦³çš„ãƒ­ãƒƒã‚¯: æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯updated_atã‚’æ¤œè¨¼
    if expected_updated_at is not None and pd.notna(expected_updated_at):
        params.append(bigquery.ScalarQueryParameter("expected_updated_at", "TIMESTAMP", expected_updated_at))
        query = f"""
        MERGE `{CHECK_LOGS_TABLE}` T
        USING (SELECT @source_url AS source_url, @year AS year, @month AS month) S
        ON T.source_url = S.source_url AND T.year = S.year AND T.month = S.month
        WHEN MATCHED AND T.updated_at = @expected_updated_at THEN
          UPDATE SET
            status = @status, checker_email = @checker_email, memo = @memo,
            action_log = @action_log, updated_at = CURRENT_TIMESTAMP()
        WHEN NOT MATCHED THEN
          INSERT (source_url, year, month, status, checker_email, memo, action_log, updated_at)
          VALUES (@source_url, @year, @month, @status, @checker_email, @memo, @action_log, CURRENT_TIMESTAMP())
        """
    else:
        query = f"""
        MERGE `{CHECK_LOGS_TABLE}` T
        USING (SELECT @source_url AS source_url, @year AS year, @month AS month) S
        ON T.source_url = S.source_url AND T.year = S.year AND T.month = S.month
        WHEN MATCHED THEN
          UPDATE SET
            status = @status, checker_email = @checker_email, memo = @memo,
            action_log = @action_log, updated_at = CURRENT_TIMESTAMP()
        WHEN NOT MATCHED THEN
          INSERT (source_url, year, month, status, checker_email, memo, action_log, updated_at)
          VALUES (@source_url, @year, @month, @status, @checker_email, @memo, @action_log, CURRENT_TIMESTAMP())
        """

    job_config = bigquery.QueryJobConfig(query_parameters=params)
    result = client.query(query, job_config=job_config).result()

    # æ¥½è¦³çš„ãƒ­ãƒƒã‚¯ç«¶åˆæ¤œå‡º
    if expected_updated_at is not None and pd.notna(expected_updated_at) and result.num_dml_affected_rows == 0:
        raise ValueError("åˆ¥ã®ãƒã‚§ãƒƒã‚¯è€…ãŒå…ˆã«æ›´æ–°ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")

    load_check_data.clear()


# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ ---
try:
    df = load_check_data(selected_year, selected_month)
except Exception as e:
    logger.error("ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: %s", e, exc_info=True)
    st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

if df.empty:
    st.info("ãƒ¡ãƒ³ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

# ãƒ‡ãƒ¼ã‚¿åŠ å·¥
for col in ["hours", "compensation", "dx_subsidy", "reimbursement", "total_amount"]:
    df[f"{col}_num"] = df[col].apply(clean_numeric_scalar)
df["check_status"] = df["check_status"].fillna("æœªç¢ºèª")
df = fill_empty_nickname(df)


# --- KPIã‚«ãƒ¼ãƒ‰ ---
total = len(df)
counts = df["check_status"].value_counts()

k1, k2, k3, k4, k5 = st.columns(5)
with k1:
    render_kpi("ç¢ºèªå®Œäº†", f"{counts.get('ç¢ºèªå®Œäº†', 0)} / {total}")
with k2:
    render_kpi("ç¢ºèªä¸­", str(counts.get("ç¢ºèªä¸­", 0)))
with k3:
    render_kpi("å·®æˆ»ã—", str(counts.get("å·®æˆ»ã—", 0)))
with k4:
    render_kpi("æœªç¢ºèª", str(counts.get("æœªç¢ºèª", 0)))
with k5:
    mc_done = df["monthly_complete"].apply(_is_complete).sum()
    render_kpi("æœˆç· ã‚å®Œäº†", f"{mc_done} / {total}")

# --- é€²æ—ãƒãƒ¼ ---
completed = counts.get("ç¢ºèªå®Œäº†", 0)
progress_val = completed / total if total > 0 else 0
st.progress(progress_val, text=f"ãƒã‚§ãƒƒã‚¯é€²æ—: {completed}/{total} ä»¶å®Œäº†")

filtered = df.copy()
if status_filter != "ã™ã¹ã¦":
    filtered = filtered[filtered["check_status"] == status_filter]
if name_search:
    filtered = filtered[filtered["nickname"].str.contains(name_search, case=False, na=False)]

st.markdown(f'<div class="count-badge">{len(filtered)} ä»¶</div>', unsafe_allow_html=True)


# --- ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ« ---
display_df = pd.DataFrame({
    "åå‰": filtered["nickname"],
    "æ™‚é–“": filtered["hours_num"],
    "å ±é…¬": filtered["compensation_num"],
    "DXè£œåŠ©": filtered["dx_subsidy_num"],
    "ç«‹æ›¿": filtered["reimbursement_num"],
    "ç·é¡": filtered["total_amount_num"],
    "æœˆç· ã‚": filtered["monthly_complete"].apply(lambda x: "â—‹" if _is_complete(x) else "Ã—"),
    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": filtered["check_status"].apply(lambda x: f"{STATUS_ICONS.get(x, '')} {x}"),
    "æ‹…å½“": filtered["checker_email"].fillna(""),
    "ãƒ¡ãƒ¢": filtered["memo"].fillna(""),
})

st.dataframe(
    display_df,
    use_container_width=True,
    hide_index=True,
    column_config={
        "æ™‚é–“": st.column_config.NumberColumn(format="%.1f"),
        "å ±é…¬": st.column_config.NumberColumn(format="Â¥%d"),
        "DXè£œåŠ©": st.column_config.NumberColumn(format="Â¥%d"),
        "ç«‹æ›¿": st.column_config.NumberColumn(format="Â¥%d"),
        "ç·é¡": st.column_config.NumberColumn(format="Â¥%d"),
    },
)


# --- ãƒ¡ãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯ ---
st.divider()

if filtered.empty:
    st.info("è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

st.markdown("""<div class="check-flow-hint">
    <b>ä½¿ã„æ–¹:</b> ä¸‹ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã§ãƒ¡ãƒ³ãƒãƒ¼ã‚’é¸æŠ â†’ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèªçŠ¶æ…‹ã‚’æ›´æ–°
</div>""", unsafe_allow_html=True)

# ãƒ¡ãƒ³ãƒãƒ¼é¸æŠ + ã€Œæ¬¡ã®æœªç¢ºèªã¸ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
unchecked_indices = [i for i in filtered.index if filtered.loc[i, "check_status"] == "æœªç¢ºèª"]
sel_col, nav_col = st.columns([3, 1])

indices = filtered.index.tolist()
with sel_col:
    selected_idx = st.selectbox(
        "ãƒ¡ãƒ³ãƒãƒ¼ã‚’é¸æŠ", indices,
        format_func=lambda i: f"{STATUS_ICONS.get(filtered.loc[i, 'check_status'], '')} {filtered.loc[i, 'nickname']}",
        key="chk_member",
    )

with nav_col:
    st.markdown("<div style='height: 1.6rem'></div>", unsafe_allow_html=True)
    remaining = len(unchecked_indices)
    if remaining > 0:
        # ç¾åœ¨é¸æŠä¸­ã®æ¬¡ã®æœªç¢ºèªã‚’æ¢ã™
        next_candidates = [i for i in unchecked_indices if i != selected_idx]
        if next_candidates and st.button(f"æ¬¡ã®æœªç¢ºèªã¸ ({remaining}ä»¶)", key="next_unchecked", use_container_width=True):
            st.session_state["chk_member"] = next_candidates[0]
            st.rerun()
    else:
        st.success("å…¨ä»¶ç¢ºèªæ¸ˆã¿", icon="ğŸ‰")

member = filtered.loc[selected_idx]
src = member["report_url"]
current_status = member["check_status"]
current_memo = member["memo"] if pd.notna(member["memo"]) else ""
widget_key = f"{src}_{selected_year}_{selected_month}"
expected_ts = member["check_updated_at"] if pd.notna(member.get("check_updated_at")) else None

with st.container(border=True):
    # ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆåå‰ + ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒªãƒ³ã‚¯ï¼‰
    h1, h2 = st.columns([3, 1])
    with h1:
        st.markdown(f"### {member['nickname']}")
    with h2:
        if pd.notna(src) and src:
            st.link_button("ğŸ“„ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ", src, use_container_width=True)

    # hojoãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    d1, d2, d3, d4, d5, d6 = st.columns(6)
    with d1:
        st.metric("æ™‚é–“", f"{clean_numeric_scalar(member['hours']):.1f}")
    with d2:
        st.metric("å ±é…¬", f"Â¥{clean_numeric_scalar(member['compensation']):,.0f}")
    with d3:
        st.metric("DXè£œåŠ©", f"Â¥{clean_numeric_scalar(member['dx_subsidy']):,.0f}")
    with d4:
        st.metric("ç«‹æ›¿", f"Â¥{clean_numeric_scalar(member['reimbursement']):,.0f}")
    with d5:
        st.metric("ç·é¡", f"Â¥{clean_numeric_scalar(member['total_amount']):,.0f}")
    with d6:
        st.metric("æœˆç· ã‚", "â—‹" if _is_complete(member["monthly_complete"]) else "Ã—")

    st.divider()

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´ï¼ˆãƒœã‚¿ãƒ³å¼ â€” ã‚¯ãƒªãƒƒã‚¯ã§å³åº§ã«ä¿å­˜ï¼‰
    st.markdown('<div class="status-section-label">ãƒã‚§ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹</div>', unsafe_allow_html=True)
    btn_cols = st.columns(len(CHECK_STATUSES))
    for i, status in enumerate(CHECK_STATUSES):
        with btn_cols[i]:
            is_current = status == current_status
            if st.button(
                f"{STATUS_ICONS[status]} {status}",
                key=f"btn_{status}_{widget_key}",
                disabled=is_current,
                type="primary" if is_current else "secondary",
                use_container_width=True,
            ):
                try:
                    save_check(
                        src, selected_year, selected_month,
                        status, current_memo, email,
                        member["action_log"],
                        f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {current_status} â†’ {status}",
                        expected_updated_at=expected_ts,
                    )
                    st.toast(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€Œ{status}ã€ã«æ›´æ–°ã—ã¾ã—ãŸ")
                    st.rerun()
                except ValueError as e:
                    st.warning(str(e))
                    load_check_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ¡ãƒ¢
    new_memo = st.text_area("ãƒ¡ãƒ¢", value=current_memo, key=f"me_{widget_key}", height=80, max_chars=1000)
    if st.button("ãƒ¡ãƒ¢ã‚’ä¿å­˜", key=f"sv_{widget_key}", use_container_width=False):
        if new_memo != current_memo:
            try:
                save_check(
                    src, selected_year, selected_month,
                    current_status, new_memo, email,
                    member["action_log"], "ãƒ¡ãƒ¢æ›´æ–°",
                    expected_updated_at=expected_ts,
                )
                st.toast("ãƒ¡ãƒ¢ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                st.rerun()
            except ValueError as e:
                st.warning(str(e))
                load_check_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("å¤‰æ›´ãŒã‚ã‚Šã¾ã›ã‚“")

    # æ“ä½œãƒ­ã‚°
    with st.expander("æ“ä½œãƒ­ã‚°"):
        log_str = member["action_log"]
        if pd.notna(log_str) and log_str:
            try:
                logs = json.loads(log_str)
                if logs:
                    for entry in reversed(logs):
                        ts = entry.get("ts", "")[:19].replace("T", " ")
                        user = entry.get("user", "")
                        action = entry.get("action", "")
                        st.markdown(f"**{ts}** {user} - {action}")
                else:
                    st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
            except (json.JSONDecodeError, TypeError):
                st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
        else:
            st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
