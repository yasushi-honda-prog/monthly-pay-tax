"""æ¥­å‹™ãƒã‚§ãƒƒã‚¯ç®¡ç†è¡¨ï¼ˆchecker/adminå°‚ç”¨ï¼‰

ãƒ¡ãƒ³ãƒãƒ¼ã®è£œåŠ©ï¼†ç«‹æ›¿å ±å‘Šã‚’ç¢ºèªã—ã€ãƒã‚§ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»ãƒ¡ãƒ¢ã‚’ç®¡ç†ã™ã‚‹ã€‚
"""

import json
import logging
from datetime import datetime, timezone

import pandas as pd
import streamlit as st
from google.cloud import bigquery

from lib.auth import require_checker
from lib.bq_client import get_bq_client
from lib.constants import PROJECT_ID, DATASET, CHECK_LOGS_TABLE
from lib.ui_helpers import clean_numeric_scalar, fill_empty_nickname, render_kpi, render_sidebar_year_month

logger = logging.getLogger(__name__)

# --- èªè¨¼ãƒã‚§ãƒƒã‚¯ ---
email = st.session_state.get("user_email", "")
role = st.session_state.get("user_role", "")
require_checker(email, role)

st.header("æ¥­å‹™ãƒã‚§ãƒƒã‚¯ç®¡ç†è¡¨")
st.caption("ãƒ¡ãƒ³ãƒãƒ¼ã®è£œåŠ©ï¼†ç«‹æ›¿å ±å‘Šã‚’ç¢ºèªãƒ»ç®¡ç†ã—ã¾ã™")

CHECK_STATUSES = ["æœªç¢ºèª", "ç¢ºèªä¸­", "ç¢ºèªå®Œäº†", "å·®æˆ»ã—"]
STATUS_DISPLAY = {
    "æœªç¢ºèª": "â¬œ æœªç¢ºèª", "ç¢ºèªä¸­": "ğŸ”µ ç¢ºèªä¸­",
    "ç¢ºèªå®Œäº†": "âœ… ç¢ºèªå®Œäº†", "å·®æˆ»ã—": "ğŸ”´ å·®æˆ»ã—",
}
DISPLAY_TO_STATUS = {v: k for k, v in STATUS_DISPLAY.items()}


def _is_complete(val) -> bool:
    """æœˆç· ã‚å®Œäº†åˆ¤å®š"""
    return str(val).strip().lower() in ("true", "1", "â—‹", "æ¸ˆ")


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆå‰åŠ: æœŸé–“ãƒ»ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰---
with st.sidebar:
    st.markdown("### âœ… æ¥­å‹™ãƒã‚§ãƒƒã‚¯")
    st.divider()

    selected_year, selected_month = render_sidebar_year_month(
        year_key="check_year", month_key="check_month",
    )

    st.markdown('<div class="sidebar-section-title">ãƒ•ã‚£ãƒ«ã‚¿</div>', unsafe_allow_html=True)
    status_filter = st.selectbox(
        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", ["ã™ã¹ã¦"] + CHECK_STATUSES, key="chk_filter",
    )


# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
@st.cache_data(ttl=300)
def load_check_data(year: int, month: int):
    """ãƒ¡ãƒ³ãƒãƒ¼ + hojo + check_logs ã‚’çµåˆã—ã¦å–å¾—"""
    client = get_bq_client()
    query = f"""
    SELECT
        m.report_url,
        m.nickname,
        m.member_id,
        h.hours,
        h.compensation,
        h.dx_subsidy,
        h.reimbursement,
        h.total_amount,
        h.monthly_complete,
        cl.status AS check_status,
        cl.checker_email,
        cl.memo,
        cl.action_log,
        cl.updated_at AS check_updated_at
    FROM `{PROJECT_ID}.{DATASET}.members` m
    LEFT JOIN `{PROJECT_ID}.{DATASET}.v_hojo_enriched` h
        ON m.report_url = h.source_url
        AND h.year = @year AND h.month = @month
    LEFT JOIN `{CHECK_LOGS_TABLE}` cl
        ON m.report_url = cl.source_url
        AND cl.year = @year AND cl.month = @month
    WHERE m.report_url IS NOT NULL
    ORDER BY m.nickname
    """
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("year", "INT64", year),
            bigquery.ScalarQueryParameter("month", "INT64", month),
        ]
    )
    return client.query(query, job_config=job_config).to_dataframe()


def save_check(source_url, year, month, status, memo, checker_email, existing_log, action_desc, expected_updated_at=None):
    """ãƒã‚§ãƒƒã‚¯ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆMERGE + æ¥½è¦³çš„ãƒ­ãƒƒã‚¯ï¼‰"""
    client = get_bq_client()

    # æ“ä½œãƒ­ã‚°è¿½è¨˜ï¼ˆå‹å®‰å…¨ï¼‰
    try:
        logs = json.loads(existing_log) if existing_log and pd.notna(existing_log) else []
        if not isinstance(logs, list):
            logs = []
    except (json.JSONDecodeError, TypeError):
        logs = []
    logs = [e for e in logs if isinstance(e, dict)]
    logs.append({
        "ts": datetime.now(timezone.utc).isoformat(),
        "user": checker_email,
        "action": action_desc,
    })
    new_log = json.dumps(logs, ensure_ascii=False)

    params = [
        bigquery.ScalarQueryParameter("source_url", "STRING", source_url),
        bigquery.ScalarQueryParameter("year", "INT64", year),
        bigquery.ScalarQueryParameter("month", "INT64", month),
        bigquery.ScalarQueryParameter("status", "STRING", status),
        bigquery.ScalarQueryParameter("checker_email", "STRING", checker_email),
        bigquery.ScalarQueryParameter("memo", "STRING", memo or None),
        bigquery.ScalarQueryParameter("action_log", "STRING", new_log),
    ]

    # æ¥½è¦³çš„ãƒ­ãƒƒã‚¯: æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯updated_atã‚’æ¤œè¨¼
    if expected_updated_at is not None and pd.notna(expected_updated_at):
        params.append(bigquery.ScalarQueryParameter("expected_updated_at", "TIMESTAMP", expected_updated_at))
        query = f"""
        MERGE `{CHECK_LOGS_TABLE}` T
        USING (SELECT @source_url AS source_url, @year AS year, @month AS month) S
        ON T.source_url = S.source_url AND T.year = S.year AND T.month = S.month
        WHEN MATCHED AND T.updated_at = @expected_updated_at THEN
          UPDATE SET
            status = @status, checker_email = @checker_email, memo = @memo,
            action_log = @action_log, updated_at = CURRENT_TIMESTAMP()
        WHEN NOT MATCHED THEN
          INSERT (source_url, year, month, status, checker_email, memo, action_log, updated_at)
          VALUES (@source_url, @year, @month, @status, @checker_email, @memo, @action_log, CURRENT_TIMESTAMP())
        """
    else:
        query = f"""
        MERGE `{CHECK_LOGS_TABLE}` T
        USING (SELECT @source_url AS source_url, @year AS year, @month AS month) S
        ON T.source_url = S.source_url AND T.year = S.year AND T.month = S.month
        WHEN MATCHED THEN
          UPDATE SET
            status = @status, checker_email = @checker_email, memo = @memo,
            action_log = @action_log, updated_at = CURRENT_TIMESTAMP()
        WHEN NOT MATCHED THEN
          INSERT (source_url, year, month, status, checker_email, memo, action_log, updated_at)
          VALUES (@source_url, @year, @month, @status, @checker_email, @memo, @action_log, CURRENT_TIMESTAMP())
        """

    job_config = bigquery.QueryJobConfig(query_parameters=params)
    result = client.query(query, job_config=job_config).result()

    # æ¥½è¦³çš„ãƒ­ãƒƒã‚¯ç«¶åˆæ¤œå‡º
    if expected_updated_at is not None and pd.notna(expected_updated_at) and result.num_dml_affected_rows == 0:
        raise ValueError("åˆ¥ã®ãƒã‚§ãƒƒã‚¯è€…ãŒå…ˆã«æ›´æ–°ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")

    load_check_data.clear()


# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ ---
try:
    df = load_check_data(selected_year, selected_month)
except Exception as e:
    logger.error("ãƒã‚§ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: %s", e, exc_info=True)
    st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

if df.empty:
    st.info("ãƒ¡ãƒ³ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

# ãƒ‡ãƒ¼ã‚¿åŠ å·¥
for col in ["hours", "compensation", "dx_subsidy", "reimbursement", "total_amount"]:
    df[f"{col}_num"] = df[col].apply(clean_numeric_scalar)
df["check_status"] = df["check_status"].fillna("æœªç¢ºèª")
df = fill_empty_nickname(df)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆå¾ŒåŠ: ãƒ¡ãƒ³ãƒãƒ¼é¸æŠï¼‰---
with st.sidebar:
    st.markdown('<div class="sidebar-section-title">ãƒ¡ãƒ³ãƒãƒ¼</div>', unsafe_allow_html=True)
    member_search = st.text_input(
        "æ¤œç´¢", key="chk_search", placeholder="åå‰ã§çµã‚Šè¾¼ã¿...",
        label_visibility="collapsed",
    )

    all_members = sorted(df["nickname"].unique().tolist())
    if member_search:
        display_members = [m for m in all_members if member_search.lower() in m.lower()]
    else:
        display_members = all_members

    col_a, col_b = st.columns(2)
    with col_a:
        if st.button("å…¨é¸æŠ", key="chk_all", use_container_width=True):
            for m in display_members:
                st.session_state[f"chk_{m}"] = True
    with col_b:
        if st.button("å…¨è§£é™¤", key="chk_clear", use_container_width=True):
            for m in display_members:
                st.session_state[f"chk_{m}"] = False

    selected_members = []
    with st.container(height=250):
        for m in display_members:
            if st.checkbox(m, key=f"chk_{m}"):
                selected_members.append(m)

    count = len(selected_members)
    total_members = len(all_members)
    if count == 0:
        st.caption(f"å…¨ {total_members} åè¡¨ç¤ºä¸­")
    else:
        st.caption(f"{count} / {total_members} åã‚’é¸æŠä¸­")


# --- KPIã‚«ãƒ¼ãƒ‰ ---
total = len(df)
counts = df["check_status"].value_counts()

k1, k2, k3, k4, k5 = st.columns(5)
with k1:
    render_kpi("ç¢ºèªå®Œäº†", f"{counts.get('ç¢ºèªå®Œäº†', 0)} / {total}")
with k2:
    render_kpi("ç¢ºèªä¸­", str(counts.get("ç¢ºèªä¸­", 0)))
with k3:
    render_kpi("å·®æˆ»ã—", str(counts.get("å·®æˆ»ã—", 0)))
with k4:
    render_kpi("æœªç¢ºèª", str(counts.get("æœªç¢ºèª", 0)))
with k5:
    mc_done = df["monthly_complete"].apply(_is_complete).sum()
    render_kpi("æœˆç· ã‚å®Œäº†", f"{mc_done} / {total}")

# --- é€²æ—ãƒãƒ¼ ---
completed = counts.get("ç¢ºèªå®Œäº†", 0)
progress_val = completed / total if total > 0 else 0
st.progress(progress_val, text=f"ãƒã‚§ãƒƒã‚¯é€²æ—: {completed}/{total} ä»¶å®Œäº†")

filtered = df.copy()
if status_filter != "ã™ã¹ã¦":
    filtered = filtered[filtered["check_status"] == status_filter]
if selected_members:
    filtered = filtered[filtered["nickname"].isin(selected_members)]

st.markdown(f'<div class="count-badge">{len(filtered)} ä»¶</div>', unsafe_allow_html=True)


# --- ä¸€è¦§ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆç›´æ¥ç·¨é›†ï¼‰ ---
if filtered.empty:
    st.info("è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

edit_df = pd.DataFrame({
    "åå‰": filtered["nickname"].values,
    "æ™‚é–“": filtered["hours_num"].values,
    "å ±é…¬": filtered["compensation_num"].values,
    "DXè£œåŠ©": filtered["dx_subsidy_num"].values,
    "ç«‹æ›¿": filtered["reimbursement_num"].values,
    "ç·é¡": filtered["total_amount_num"].values,
    "æœˆç· ã‚": filtered["monthly_complete"].apply(lambda x: "â—‹" if _is_complete(x) else "Ã—").values,
    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": filtered["check_status"].map(STATUS_DISPLAY).values,
    "ãƒ¡ãƒ¢": filtered["memo"].fillna("").values,
})

edited_df = st.data_editor(
    edit_df,
    column_config={
        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": st.column_config.SelectboxColumn(
            options=list(STATUS_DISPLAY.values()), required=True,
        ),
        "ãƒ¡ãƒ¢": st.column_config.TextColumn(max_chars=1000),
        "æ™‚é–“": st.column_config.NumberColumn(format="%.1f"),
        "å ±é…¬": st.column_config.NumberColumn(format="Â¥%d"),
        "DXè£œåŠ©": st.column_config.NumberColumn(format="Â¥%d"),
        "ç«‹æ›¿": st.column_config.NumberColumn(format="Â¥%d"),
        "ç·é¡": st.column_config.NumberColumn(format="Â¥%d"),
    },
    disabled=["åå‰", "æ™‚é–“", "å ±é…¬", "DXè£œåŠ©", "ç«‹æ›¿", "ç·é¡", "æœˆç· ã‚"],
    use_container_width=True,
    hide_index=True,
    key="check_editor",
)

# å¤‰æ›´æ¤œå‡º & ä¸€æ‹¬ä¿å­˜
indices = filtered.index.tolist()
changes = []
for i in range(len(edit_df)):
    orig_display = edit_df.iloc[i]["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"]
    orig_memo = edit_df.iloc[i]["ãƒ¡ãƒ¢"]
    new_display = edited_df.iloc[i]["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"]
    new_memo = edited_df.iloc[i]["ãƒ¡ãƒ¢"]
    orig_status = DISPLAY_TO_STATUS.get(orig_display, orig_display)
    new_status = DISPLAY_TO_STATUS.get(new_display, new_display)

    if new_status != orig_status or new_memo != orig_memo:
        actions = []
        if new_status != orig_status:
            actions.append(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {orig_status} â†’ {new_status}")
        if new_memo != orig_memo:
            actions.append("ãƒ¡ãƒ¢æ›´æ–°")
        changes.append((indices[i], new_status, new_memo, actions))

if changes:
    saved = 0
    for idx, new_status, new_memo, actions in changes:
        member = filtered.loc[idx]
        try:
            save_check(
                member["report_url"], selected_year, selected_month,
                new_status, new_memo, email,
                member["action_log"], " / ".join(actions),
                expected_updated_at=member["check_updated_at"] if pd.notna(member.get("check_updated_at")) else None,
            )
            saved += 1
        except ValueError as e:
            st.error(f"ç«¶åˆã‚¨ãƒ©ãƒ¼ ({member['nickname']}): {e}")
            load_check_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({member['nickname']}): {e}")
            load_check_data.clear()
            st.rerun()

    st.toast(f"{saved}ä»¶ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    load_check_data.clear()
    st.rerun()


# --- æ“ä½œãƒ­ã‚° ---
st.divider()
with st.expander("æ“ä½œãƒ­ã‚°ã‚’ç¢ºèª"):
    log_member = st.selectbox(
        "ãƒ¡ãƒ³ãƒãƒ¼", indices,
        format_func=lambda i: filtered.loc[i, "nickname"],
        key="log_member",
    )
    log_str = filtered.loc[log_member, "action_log"]
    if pd.notna(log_str) and log_str:
        try:
            logs = json.loads(log_str)
            if logs:
                for entry in reversed(logs):
                    ts = entry.get("ts", "")[:19].replace("T", " ")
                    user = entry.get("user", "")
                    action = entry.get("action", "")
                    st.markdown(f"**{ts}** {user} â€” {action}")
            else:
                st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
        except (json.JSONDecodeError, TypeError):
            st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
    else:
        st.caption("æ“ä½œãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“")
